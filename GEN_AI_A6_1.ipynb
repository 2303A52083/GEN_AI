{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsz9b6Y4GHfafDKZLRY31L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52083/GEN_AI/blob/main/GEN_AI_A6_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"Housing.csv\")\n",
        "\n",
        "# Encode categorical variables using one-hot encoding\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# Convert data to float32 for TensorFlow compatibility\n",
        "data = data.astype(np.float32)\n",
        "\n",
        "# Split data\n",
        "X = data.drop('price', axis=1)\n",
        "y = data['price']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build ANN model with Input() layer\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(15, activation='tanh'),\n",
        "    Dense(20, activation='tanh'),\n",
        "    Dense(15, activation='tanh'),\n",
        "    Dense(1)  # Regression output (no activation)\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mse'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save the model in .keras format\n",
        "model.save(\"housing_price_model_6.1.keras\")\n",
        "\n",
        "# Load and compile the saved model\n",
        "loaded_model = keras.models.load_model(\"housing_price_model_6.1.keras\")\n",
        "loaded_model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mse'])\n",
        "\n",
        "# Evaluate performance\n",
        "train_pred = loaded_model.predict(X_train)\n",
        "test_pred = loaded_model.predict(X_test)\n",
        "\n",
        "print(\"Training MSE:\", mean_squared_error(y_train, train_pred))\n",
        "print(\"Testing MSE:\", mean_squared_error(y_test, test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVEHebIIx10d",
        "outputId": "bded131b-1759-42a4-9337-97cacb942921"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8864344834048.0000 - mse: 8864344834048.0000 - val_loss: 4310988750848.0000 - val_mse: 4310988750848.0000\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2848880328704.0000 - mse: 2848880328704.0000 - val_loss: 4401140334592.0000 - val_mse: 4401140334592.0000\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3173810962432.0000 - mse: 3173810962432.0000 - val_loss: 4357405540352.0000 - val_mse: 4357405540352.0000\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3315665731584.0000 - mse: 3315665731584.0000 - val_loss: 4307568558080.0000 - val_mse: 4307568558080.0000\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2966506438656.0000 - mse: 2966506438656.0000 - val_loss: 4349384458240.0000 - val_mse: 4349384458240.0000\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3395482288128.0000 - mse: 3395482288128.0000 - val_loss: 4311109074944.0000 - val_mse: 4311109074944.0000\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3317929607168.0000 - mse: 3317929607168.0000 - val_loss: 4451597287424.0000 - val_mse: 4451597287424.0000\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3766321152000.0000 - mse: 3766321152000.0000 - val_loss: 4322109947904.0000 - val_mse: 4322109947904.0000\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3216810967040.0000 - mse: 3216810967040.0000 - val_loss: 4307158564864.0000 - val_mse: 4307158564864.0000\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3074086666240.0000 - mse: 3074086666240.0000 - val_loss: 4409935265792.0000 - val_mse: 4409935265792.0000\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3471741026304.0000 - mse: 3471741026304.0000 - val_loss: 4343842471936.0000 - val_mse: 4343842471936.0000\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3815729004544.0000 - mse: 3815729004544.0000 - val_loss: 4308562608128.0000 - val_mse: 4308562608128.0000\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3549639999488.0000 - mse: 3549639999488.0000 - val_loss: 4306839797760.0000 - val_mse: 4306839797760.0000\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3183334129664.0000 - mse: 3183334129664.0000 - val_loss: 4323109765120.0000 - val_mse: 4323109765120.0000\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3112745304064.0000 - mse: 3112745304064.0000 - val_loss: 4307388989440.0000 - val_mse: 4307388989440.0000\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3470189133824.0000 - mse: 3470189133824.0000 - val_loss: 4365785235456.0000 - val_mse: 4365785235456.0000\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3313085186048.0000 - mse: 3313085186048.0000 - val_loss: 4476544483328.0000 - val_mse: 4476544483328.0000\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2847587696640.0000 - mse: 2847587696640.0000 - val_loss: 4307751010304.0000 - val_mse: 4307751010304.0000\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3117629833216.0000 - mse: 3117629833216.0000 - val_loss: 4336451321856.0000 - val_mse: 4336451321856.0000\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3191889199104.0000 - mse: 3191889199104.0000 - val_loss: 4307217547264.0000 - val_mse: 4307217547264.0000\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2828144738304.0000 - mse: 2828144738304.0000 - val_loss: 4318563926016.0000 - val_mse: 4318563926016.0000\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3289094029312.0000 - mse: 3289094029312.0000 - val_loss: 4306469388288.0000 - val_mse: 4306469388288.0000\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3606536257536.0000 - mse: 3606536257536.0000 - val_loss: 4337957076992.0000 - val_mse: 4337957076992.0000\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3472592207872.0000 - mse: 3472592207872.0000 - val_loss: 4306808864768.0000 - val_mse: 4306808864768.0000\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3398798671872.0000 - mse: 3398798671872.0000 - val_loss: 4327587184640.0000 - val_mse: 4327587184640.0000\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3185567596544.0000 - mse: 3185567596544.0000 - val_loss: 4431550611456.0000 - val_mse: 4431550611456.0000\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3370208722944.0000 - mse: 3370208722944.0000 - val_loss: 4317676568576.0000 - val_mse: 4317676568576.0000\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2796444188672.0000 - mse: 2796444188672.0000 - val_loss: 4365171294208.0000 - val_mse: 4365171294208.0000\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2948425842688.0000 - mse: 2948425842688.0000 - val_loss: 4306507137024.0000 - val_mse: 4306507137024.0000\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3242061201408.0000 - mse: 3242061201408.0000 - val_loss: 4311062413312.0000 - val_mse: 4311062413312.0000\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2934624747520.0000 - mse: 2934624747520.0000 - val_loss: 4323339141120.0000 - val_mse: 4323339141120.0000\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3323248246784.0000 - mse: 3323248246784.0000 - val_loss: 4321681866752.0000 - val_mse: 4321681866752.0000\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2965104492544.0000 - mse: 2965104492544.0000 - val_loss: 4327934525440.0000 - val_mse: 4327934525440.0000\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3492324835328.0000 - mse: 3492324835328.0000 - val_loss: 4314978058240.0000 - val_mse: 4314978058240.0000\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2820282253312.0000 - mse: 2820282253312.0000 - val_loss: 4347674230784.0000 - val_mse: 4347674230784.0000\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3475280494592.0000 - mse: 3475280494592.0000 - val_loss: 4307762282496.0000 - val_mse: 4307762282496.0000\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3035608645632.0000 - mse: 3035608645632.0000 - val_loss: 4313125486592.0000 - val_mse: 4313125486592.0000\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2969247416320.0000 - mse: 2969247416320.0000 - val_loss: 4314106953728.0000 - val_mse: 4314106953728.0000\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3285911601152.0000 - mse: 3285911601152.0000 - val_loss: 4309791014912.0000 - val_mse: 4309791014912.0000\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2903797137408.0000 - mse: 2903797137408.0000 - val_loss: 4311535321088.0000 - val_mse: 4311535321088.0000\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3056918331392.0000 - mse: 3056918331392.0000 - val_loss: 4350313758720.0000 - val_mse: 4350313758720.0000\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3158373564416.0000 - mse: 3158373564416.0000 - val_loss: 4308957396992.0000 - val_mse: 4308957396992.0000\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3008176848896.0000 - mse: 3008176848896.0000 - val_loss: 4312910004224.0000 - val_mse: 4312910004224.0000\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3183895904256.0000 - mse: 3183895904256.0000 - val_loss: 4314206568448.0000 - val_mse: 4314206568448.0000\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3391577128960.0000 - mse: 3391577128960.0000 - val_loss: 4306793922560.0000 - val_mse: 4306793922560.0000\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3390455152640.0000 - mse: 3390455152640.0000 - val_loss: 4320479412224.0000 - val_mse: 4320479412224.0000\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2960275275776.0000 - mse: 2960275275776.0000 - val_loss: 4360467120128.0000 - val_mse: 4360467120128.0000\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3193551192064.0000 - mse: 3193551192064.0000 - val_loss: 4306892750848.0000 - val_mse: 4306892750848.0000\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3127418290176.0000 - mse: 3127418290176.0000 - val_loss: 4309542240256.0000 - val_mse: 4309542240256.0000\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3300770447360.0000 - mse: 3300770447360.0000 - val_loss: 4417818460160.0000 - val_mse: 4417818460160.0000\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3439826305024.0000 - mse: 3439826305024.0000 - val_loss: 4341046181888.0000 - val_mse: 4341046181888.0000\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3381680930816.0000 - mse: 3381680930816.0000 - val_loss: 4367662448640.0000 - val_mse: 4367662448640.0000\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3336350990336.0000 - mse: 3336350990336.0000 - val_loss: 4577988444160.0000 - val_mse: 4577988444160.0000\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2385697832960.0000 - mse: 2385697832960.0000 - val_loss: 4306926567424.0000 - val_mse: 4306926567424.0000\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3273579298816.0000 - mse: 3273579298816.0000 - val_loss: 4310105325568.0000 - val_mse: 4310105325568.0000\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3323603451904.0000 - mse: 3323603451904.0000 - val_loss: 4306461786112.0000 - val_mse: 4306461786112.0000\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3363902062592.0000 - mse: 3363902062592.0000 - val_loss: 4308804042752.0000 - val_mse: 4308804042752.0000\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3276457902080.0000 - mse: 3276457902080.0000 - val_loss: 4317305110528.0000 - val_mse: 4317305110528.0000\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3097598099456.0000 - mse: 3097598099456.0000 - val_loss: 4306675695616.0000 - val_mse: 4306675695616.0000\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3188595097600.0000 - mse: 3188595097600.0000 - val_loss: 4316420898816.0000 - val_mse: 4316420898816.0000\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3540778483712.0000 - mse: 3540778483712.0000 - val_loss: 4328763949056.0000 - val_mse: 4328763949056.0000\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3097310003200.0000 - mse: 3097310003200.0000 - val_loss: 4312831361024.0000 - val_mse: 4312831361024.0000\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3508250345472.0000 - mse: 3508250345472.0000 - val_loss: 4331578851328.0000 - val_mse: 4331578851328.0000\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2805725134848.0000 - mse: 2805725134848.0000 - val_loss: 4491776098304.0000 - val_mse: 4491776098304.0000\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3498289397760.0000 - mse: 3498289397760.0000 - val_loss: 4328398258176.0000 - val_mse: 4328398258176.0000\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3232151109632.0000 - mse: 3232151109632.0000 - val_loss: 4306408570880.0000 - val_mse: 4306408570880.0000\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3280765714432.0000 - mse: 3280765714432.0000 - val_loss: 4326389448704.0000 - val_mse: 4326389448704.0000\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3116323307520.0000 - mse: 3116323307520.0000 - val_loss: 4311222845440.0000 - val_mse: 4311222845440.0000\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3561018884096.0000 - mse: 3561018884096.0000 - val_loss: 4307210207232.0000 - val_mse: 4307210207232.0000\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3656027996160.0000 - mse: 3656027996160.0000 - val_loss: 4307172458496.0000 - val_mse: 4307172458496.0000\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3178839146496.0000 - mse: 3178839146496.0000 - val_loss: 4308034387968.0000 - val_mse: 4308034387968.0000\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3280587980800.0000 - mse: 3280587980800.0000 - val_loss: 4318675599360.0000 - val_mse: 4318675599360.0000\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2957626834944.0000 - mse: 2957626834944.0000 - val_loss: 4307809206272.0000 - val_mse: 4307809206272.0000\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3024556654592.0000 - mse: 3024556654592.0000 - val_loss: 4323466805248.0000 - val_mse: 4323466805248.0000\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3389113237504.0000 - mse: 3389113237504.0000 - val_loss: 4321961836544.0000 - val_mse: 4321961836544.0000\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3616841400320.0000 - mse: 3616841400320.0000 - val_loss: 4357995102208.0000 - val_mse: 4357995102208.0000\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2934973399040.0000 - mse: 2934973399040.0000 - val_loss: 4310574301184.0000 - val_mse: 4310574301184.0000\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2722210250752.0000 - mse: 2722210250752.0000 - val_loss: 4340960722944.0000 - val_mse: 4340960722944.0000\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3640751292416.0000 - mse: 3640751292416.0000 - val_loss: 4383786401792.0000 - val_mse: 4383786401792.0000\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2829988659200.0000 - mse: 2829988659200.0000 - val_loss: 4313430097920.0000 - val_mse: 4313430097920.0000\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3538293096448.0000 - mse: 3538293096448.0000 - val_loss: 4309768470528.0000 - val_mse: 4309768470528.0000\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3482446725120.0000 - mse: 3482446725120.0000 - val_loss: 4326667321344.0000 - val_mse: 4326667321344.0000\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2822755581952.0000 - mse: 2822755581952.0000 - val_loss: 4306711347200.0000 - val_mse: 4306711347200.0000\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3440742498304.0000 - mse: 3440742498304.0000 - val_loss: 4347284422656.0000 - val_mse: 4347284422656.0000\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3251568115712.0000 - mse: 3251568115712.0000 - val_loss: 4366170587136.0000 - val_mse: 4366170587136.0000\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3671458578432.0000 - mse: 3671458578432.0000 - val_loss: 4474443661312.0000 - val_mse: 4474443661312.0000\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2795979931648.0000 - mse: 2795979931648.0000 - val_loss: 4306442125312.0000 - val_mse: 4306442125312.0000\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3252158726144.0000 - mse: 3252158726144.0000 - val_loss: 4353417543680.0000 - val_mse: 4353417543680.0000\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2886157991936.0000 - mse: 2886157991936.0000 - val_loss: 4353899626496.0000 - val_mse: 4353899626496.0000\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3229881204736.0000 - mse: 3229881204736.0000 - val_loss: 4307456098304.0000 - val_mse: 4307456098304.0000\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3076580179968.0000 - mse: 3076580179968.0000 - val_loss: 4307368804352.0000 - val_mse: 4307368804352.0000\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2744305057792.0000 - mse: 2744305057792.0000 - val_loss: 4670927405056.0000 - val_mse: 4670927405056.0000\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3474297716736.0000 - mse: 3474297716736.0000 - val_loss: 4354415001600.0000 - val_mse: 4354415001600.0000\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2977314373632.0000 - mse: 2977314373632.0000 - val_loss: 4306454708224.0000 - val_mse: 4306454708224.0000\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3097927352320.0000 - mse: 3097927352320.0000 - val_loss: 4312030511104.0000 - val_mse: 4312030511104.0000\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2797320798208.0000 - mse: 2797320798208.0000 - val_loss: 4321114324992.0000 - val_mse: 4321114324992.0000\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3101589504000.0000 - mse: 3101589504000.0000 - val_loss: 4307252674560.0000 - val_mse: 4307252674560.0000\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3490688008192.0000 - mse: 3490688008192.0000 - val_loss: 4311641751552.0000 - val_mse: 4311641751552.0000\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3085105364992.0000 - mse: 3085105364992.0000 - val_loss: 4362701111296.0000 - val_mse: 4362701111296.0000\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3483519942656.0000 - mse: 3483519942656.0000 - val_loss: 4307565674496.0000 - val_mse: 4307565674496.0000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Training MSE: 3141960990720.0\n",
            "Testing MSE: 4307564888064.0\n"
          ]
        }
      ]
    }
  ]
}