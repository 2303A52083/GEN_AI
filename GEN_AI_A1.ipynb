{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+IjlU1bDUJtulkLm1UpZc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52083/GEN_AI/blob/main/GEN_AI_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write Python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with the outcomes of libraries\n",
        "YActual  YP red\n",
        "20       20.5\n",
        "30       30.3\n",
        "40       40.2\n",
        "50       50.6\n",
        "60       60.7\n",
        "Tabela 1: YActual Vs. YP red"
      ],
      "metadata": {
        "id": "V-eiKtaSHjX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1gTXADYCZPj",
        "outputId": "28907364-39d4-4e8d-817b-d8f3309bb923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Metrics Calculated From Scratch:\n",
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n",
            "\n",
            "Error Metrics Calculated Using Libraries:\n",
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Table 1: YActual vs. YPred\n",
        "Y_actual = [20, 30, 40, 50, 60]\n",
        "Y_pred = [20.5, 30.3, 40.2, 50.6, 60.7]\n",
        "\n",
        "# Function to calculate error metrics from scratch\n",
        "def calculate_metrics_from_scratch(y_actual, y_pred):\n",
        "    n = len(y_actual)\n",
        "    absolute_errors = [abs(y_a - y_p) for y_a, y_p in zip(y_actual, y_pred)]\n",
        "    squared_errors = [(y_a - y_p) ** 2 for y_a, y_p in zip(y_actual, y_pred)]\n",
        "\n",
        "    mae = sum(absolute_errors) / n\n",
        "    mse = sum(squared_errors) / n\n",
        "    rmse = mse ** 0.5\n",
        "\n",
        "    return mae, mse, rmse\n",
        "\n",
        "# Calculate metrics from scratch\n",
        "mae_scratch, mse_scratch, rmse_scratch = calculate_metrics_from_scratch(Y_actual, Y_pred)\n",
        "\n",
        "# Calculate metrics using libraries\n",
        "mae_lib = mean_absolute_error(Y_actual, Y_pred)\n",
        "mse_lib = mean_squared_error(Y_actual, Y_pred)\n",
        "# Calculate RMSE by taking the square root of MSE\n",
        "rmse_lib = np.sqrt(mse_lib)  # Calculate RMSE using NumPy\n",
        "# Display results\n",
        "print(\"Error Metrics Calculated From Scratch:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_scratch}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_scratch}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_scratch}\")\n",
        "\n",
        "print(\"\\nError Metrics Calculated Using Libraries:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_lib}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_lib}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_lib}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write python code from scratch to find evaluation metrics of deep learning model.\n",
        "Actual values and deep learning model predicted values are shown in Table 2. Also compare the\n",
        "results with outcome of libraries\n",
        "YActual YP red\n",
        "0 0 1 1 2 0\n",
        "0 0 1 0 2 0\n",
        "0 1 1 2 2 1\n",
        "0 2 1 0 2 2\n",
        "0 2 1 2 2 2\n",
        "Tabela 2: YActual Vs. YP red\n",
        "• Expected Leaning Outcomes from this assignment related to python\n",
        "– Students are able to understand deep learning model metrics\n",
        "– Students are able to write code in python to find deep learning model metrics\n",
        "– Students are able to use python libraries to find deep learning model metrics\n",
        "• Naming cinvention\n",
        "– Report File Name: RollNo_Week No._Assignment No."
      ],
      "metadata": {
        "id": "_X1s7885ILVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "y_a = [0, 0, 1, 1, 2, 0, 0, 1, 0, 2, 0, 1, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2]\n",
        "y_p = [0, 0, 1, 0, 2, 0, 0, 1, 2, 2, 0, 1, 1, 2, 2, 1, 0, 2, 1, 0, 2, 2]\n",
        "def calc_acc(y_a, y_p):\n",
        "    c = sum([1 for a, p in zip(y_a, y_p) if a == p])\n",
        "    return c / len(y_a)\n",
        "def calc_cm(y_a, y_p, n_c):\n",
        "    m = np.zeros((n_c, n_c), dtype=int)\n",
        "    for a, p in zip(y_a, y_p):\n",
        "        m[a][p] += 1\n",
        "    return m\n",
        "n_c = len(set(y_a))\n",
        "acc = calc_acc(y_a, y_p)\n",
        "cm = calc_cm(y_a, y_p, n_c)\n",
        "lib_acc = accuracy_score(y_a, y_p)\n",
        "lib_cm = confusion_matrix(y_a, y_p)\n",
        "print(\"Accuracy (from scratch):\", acc)\n",
        "print(\"Confusion Matrix (from scratch):\\n\", cm)\n",
        "print(\"\\nUsing Libraries:\")\n",
        "print(\"Accuracy (library):\", lib_acc)\n",
        "print(\"Confusion Matrix (library):\\n\", lib_cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT2lzBLJH3DT",
        "outputId": "00fc4e2c-71d6-4966-c801-59fee3a73c7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (from scratch): 0.8636363636363636\n",
            "Confusion Matrix (from scratch):\n",
            " [[6 0 1]\n",
            " [1 6 0]\n",
            " [1 0 7]]\n",
            "\n",
            "Using Libraries:\n",
            "Accuracy (library): 0.8636363636363636\n",
            "Confusion Matrix (library):\n",
            " [[6 0 1]\n",
            " [1 6 0]\n",
            " [1 0 7]]\n"
          ]
        }
      ]
    }
  ]
}